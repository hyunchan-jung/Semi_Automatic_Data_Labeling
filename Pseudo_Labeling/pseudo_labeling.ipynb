{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25f6165c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:22:46.191065Z",
     "start_time": "2022-01-31T05:22:46.184073Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ac08c92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:22:46.357871Z",
     "start_time": "2022-01-31T05:22:46.345864Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "fix_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "085d187c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:22:52.979825Z",
     "start_time": "2022-01-31T05:22:46.493804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled 1 % data: 600\n",
      "labeled_data: 600, unlabeled_data: 59400\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.1307, 0.3081)\n",
    "])\n",
    "\n",
    "data_path = 'D:/Dropbox/Dropbox/Work/Study/dataset/'\n",
    "mnist_ds = list(torchvision.datasets.MNIST(data_path,\n",
    "                                           download=False,\n",
    "                                           train=True,\n",
    "                                           transform=transform))\n",
    "\n",
    "labeled_size = int(len(mnist_ds) * 0.01)\n",
    "print('labeled 1 % data:', labeled_size)\n",
    "\n",
    "labeled_ds = mnist_ds[:labeled_size]\n",
    "unlabeled_ds = mnist_ds[labeled_size:]\n",
    "print(f'labeled_data: {len(labeled_ds)}, unlabeled_data: {len(unlabeled_ds)}')\n",
    "\n",
    "mnist_dl = DataLoader(mnist_ds, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d95c548b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:22:52.994815Z",
     "start_time": "2022-01-31T05:22:52.983812Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(labeled_ds):\n",
    "    '''\n",
    "    split train_ds and validation_ds with random index of labeled_ds\n",
    "    '''\n",
    "    \n",
    "    size = len(labeled_ds)\n",
    "    validation_idx = sorted(list(np.random.choice(range(size), int(size * 0.2), replace=False)),\n",
    "                            reverse=True)\n",
    "    validation_ds = [labeled_ds[i] for i in validation_idx]\n",
    "    for i in validation_idx:\n",
    "        del labeled_ds[i]\n",
    "    train_ds = labeled_ds\n",
    "    \n",
    "    print(f'train data size: {len(train_ds)}, validation data size: {len(validation_ds)}')\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "    validation_dl = DataLoader(validation_ds, batch_size=8, shuffle=False)\n",
    "    \n",
    "    return train_dl, validation_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a323744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:22:53.010042Z",
     "start_time": "2022-01-31T05:22:52.996814Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, 2, 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, 2, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 1, 0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 5 * 5, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba1c5ab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:22:53.025045Z",
     "start_time": "2022-01-31T05:22:53.013044Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_val(train_dl, validation_dl, epochs=5):\n",
    "    '''\n",
    "    train model, return best validation accuracy\n",
    "    '''\n",
    "    \n",
    "    best_accuracy = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in train_dl:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            preds = model(imgs)\n",
    "            batch_loss = loss_fn(preds, labels)\n",
    "            train_loss.append(batch_loss.item())\n",
    "            \n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = np.array(train_loss).mean()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            class_correct = 0\n",
    "            val_loss = []\n",
    "            for imgs, labels in validation_dl:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                \n",
    "                preds = model(imgs)\n",
    "                batch_loss = loss_fn(preds, labels)\n",
    "                val_loss.append(batch_loss.item())\n",
    "                \n",
    "                y_preds = torch.max(torch.softmax(preds, dim=1), dim=1)[1]\n",
    "                c = (labels==y_preds)\n",
    "                class_correct += c.tolist().count(True)\n",
    "            val_loss = np.array(val_loss).mean()\n",
    "            accuracy = class_correct / (validation_dl.batch_size * len(validation_dl))\n",
    "            best_accuracy.append(accuracy)\n",
    "            \n",
    "        print('epoch: {}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'\n",
    "              .format(epoch, train_loss, val_loss, accuracy))\n",
    "            \n",
    "    best_accuracy = max(best_accuracy)\n",
    "    \n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "055487e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:22:53.040049Z",
     "start_time": "2022-01-31T05:22:53.026045Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_unlabeled(unlabeled_ds, threshold=0.99):\n",
    "    '''\n",
    "    if predicted label' confidence is higher then threshold,\n",
    "    labeling y as predicted y\n",
    "    '''\n",
    "    \n",
    "    unlabeled = torch.stack([i[0] for i in unlabeled_ds])\n",
    "    unlabeled_dl = DataLoader(unlabeled, batch_size=8)\n",
    "    \n",
    "    pseudo_labeled = []\n",
    "    index = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, imgs in enumerate(unlabeled_dl):\n",
    "            imgs = imgs.to(device)\n",
    "            \n",
    "            preds = model(imgs)\n",
    "            preds = torch.softmax(preds, dim=1)\n",
    "            conf_preds, y_preds = torch.max(preds, dim=1)\n",
    "            for j, confidence in enumerate(conf_preds):\n",
    "                if confidence >= threshold:\n",
    "                    pseudo_labeled.append((imgs[j].cpu(), y_preds[j].item()))\n",
    "                    idx = (i * unlabeled_dl.batch_size) + j\n",
    "                    index.append(idx)\n",
    "    \n",
    "    print(f'pseudo_labeled size: {len(pseudo_labeled)}')\n",
    "    \n",
    "    return pseudo_labeled, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1d65776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:22:53.055061Z",
     "start_time": "2022-01-31T05:22:53.042049Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_dataset(pseudo_labeled, index):\n",
    "    '''\n",
    "    add pseudo_labeled to labeled_dataset\n",
    "    '''\n",
    "    \n",
    "    for i in sorted(index, reverse=True):\n",
    "        del unlabeled_ds[i]\n",
    "    \n",
    "    labeled_ds.extend(pseudo_labeled)\n",
    "    \n",
    "    print(f'labeled size: {len(labeled_ds)}, unlabeled size: {len(unlabeled_ds)}')\n",
    "    \n",
    "    return labeled_ds, unlabeled_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "711ca565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:22:53.070066Z",
     "start_time": "2022-01-31T05:22:53.057064Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        class_correct = 0\n",
    "        for imgs, labels in mnist_dl:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            preds = model(imgs)\n",
    "            y_preds = torch.max(torch.softmax(preds, dim=1), dim=1)[1]\n",
    "            c = (labels==y_preds)\n",
    "            class_correct += c.tolist().count(True)\n",
    "        accuracy = class_correct / (mnist_dl.batch_size * len(mnist_dl))\n",
    "    print(f'evaluation accuracy: {accuracy:.4f}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66aec5ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:22:53.085070Z",
     "start_time": "2022-01-31T05:22:53.072069Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07e934d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:23:07.667834Z",
     "start_time": "2022-01-31T05:22:53.087072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 480, validation data size: 120\n",
      "epoch: 1, train_loss: 1.1118, val_loss: 0.5429, val_acc: 0.8250\n",
      "epoch: 2, train_loss: 0.2300, val_loss: 0.4343, val_acc: 0.8667\n",
      "epoch: 3, train_loss: 0.0754, val_loss: 0.5073, val_acc: 0.8333\n",
      "epoch: 4, train_loss: 0.0434, val_loss: 0.4650, val_acc: 0.8750\n",
      "epoch: 5, train_loss: 0.0073, val_loss: 0.4367, val_acc: 0.8833\n",
      "evaluation accuracy: 0.8838\n",
      "pseudo_labeled size: 34277\n",
      "labeled size: 34877, unlabeled size: 25123\n"
     ]
    }
   ],
   "source": [
    "train_dl, validation_dl = train_test_split(labeled_ds.copy())\n",
    "train_val(train_dl, validation_dl)\n",
    "evaluation()\n",
    "pseudo_labeled, index = test_unlabeled(unlabeled_ds)\n",
    "labeled_ds, unlabeled_ds = update_dataset(pseudo_labeled, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e57e994a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:23:07.682837Z",
     "start_time": "2022-01-31T05:23:07.670834Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_wrong_pseudo_labeled(mnist_ds, labeled_ds):\n",
    "    mnist_ds.sort(key=lambda x: x[0].sum())\n",
    "    labeled_ds.sort(key=lambda x: x[0].sum())\n",
    "\n",
    "    idx = 0\n",
    "    wrong_label_cnt = 0\n",
    "    for img, label in tqdm(labeled_ds[labeled_size:]):\n",
    "        for n, (img2, label2) in enumerate(mnist_ds[idx:]):\n",
    "            if (img==img2).view(-1).tolist().count(False) == 0:\n",
    "                idx += n\n",
    "                if label != label2:\n",
    "                    wrong_label_cnt += 1\n",
    "                break\n",
    "    print('pseudo labeled size: {}, wrong label count: {}, {:.2f}%'\n",
    "          .format(len(labeled_ds)-labeled_size, wrong_label_cnt, wrong_label_cnt/(len(labeled_ds)-labeled_size)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b960e0b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T05:23:24.596128Z",
     "start_time": "2022-01-31T05:23:07.684838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af91f04d0464c2696160d10447ce318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudo labeled size: 34277, wrong label count: 406, 1.18%\n"
     ]
    }
   ],
   "source": [
    "find_wrong_pseudo_labeled(mnist_ds.copy(), labeled_ds.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb58ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

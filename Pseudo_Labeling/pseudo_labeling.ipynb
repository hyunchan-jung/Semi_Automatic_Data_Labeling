{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f6165c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T17:59:35.352932Z",
     "start_time": "2022-01-30T17:59:34.467584Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac08c92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T17:59:35.382957Z",
     "start_time": "2022-01-30T17:59:35.354933Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "fix_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "085d187c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T17:59:41.972245Z",
     "start_time": "2022-01-30T17:59:35.384961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled 1 % data: 600\n",
      "labeled_data: 600, unlabeled_data: 59400\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.1307, 0.3081)\n",
    "])\n",
    "\n",
    "data_path = 'D:/Dropbox/Dropbox/Work/Study/dataset/'\n",
    "mnist_ds = list(torchvision.datasets.MNIST(data_path,\n",
    "                                           download=False,\n",
    "                                           train=True,\n",
    "                                           transform=transform))\n",
    "\n",
    "labeled_size = int(len(mnist_ds) * 0.01)\n",
    "print('labeled 1 % data:', labeled_size)\n",
    "\n",
    "labeled_ds = mnist_ds[:labeled_size]\n",
    "unlabeled_ds = mnist_ds[labeled_size:]\n",
    "print(f'labeled_data: {len(labeled_ds)}, unlabeled_data: {len(unlabeled_ds)}')\n",
    "\n",
    "mnist_dl = DataLoader(mnist_ds, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95c548b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T17:59:41.987247Z",
     "start_time": "2022-01-30T17:59:41.975244Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(labeled_ds):\n",
    "    '''\n",
    "    split train_ds and validation_ds with random index of labeled_ds\n",
    "    '''\n",
    "    \n",
    "    size = len(labeled_ds)\n",
    "    validation_idx = sorted(list(np.random.choice(range(size), int(size * 0.2), replace=False)),\n",
    "                            reverse=True)\n",
    "    validation_ds = [labeled_ds[i] for i in validation_idx]\n",
    "    for i in validation_idx:\n",
    "        del labeled_ds[i]\n",
    "    train_ds = labeled_ds\n",
    "    \n",
    "    print(f'train data size: {len(train_ds)}, validation data size: {len(validation_ds)}')\n",
    "    \n",
    "    train_dl = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "    validation_dl = DataLoader(validation_ds, batch_size=8, shuffle=False)\n",
    "    \n",
    "    return train_dl, validation_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a323744",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T17:59:42.002249Z",
     "start_time": "2022-01-30T17:59:41.989247Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, 2, 1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, 2, 1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, 1, 0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 5 * 5, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1c5ab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T17:59:42.017254Z",
     "start_time": "2022-01-30T17:59:42.004252Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_val(train_dl, validation_dl, epochs=5):\n",
    "    '''\n",
    "    train model, return best validation accuracy\n",
    "    '''\n",
    "    \n",
    "    best_accuracy = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in train_dl:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            preds = model(imgs)\n",
    "            preds = torch.log(torch.softmax(preds, dim=1))\n",
    "            batch_loss = loss_fn(preds, labels)\n",
    "            train_loss.append(batch_loss.item())\n",
    "            \n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss = np.array(train_loss).mean()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            class_correct = 0\n",
    "            val_loss = []\n",
    "            for imgs, labels in validation_dl:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                \n",
    "                preds = model(imgs)\n",
    "                preds = torch.log(torch.softmax(preds, dim=1))\n",
    "                batch_loss = loss_fn(preds, labels)\n",
    "                val_loss.append(batch_loss.item())\n",
    "                \n",
    "                c = (labels==torch.max(preds, dim=1)[1])\n",
    "                class_correct += c.tolist().count(True)\n",
    "            val_loss = np.array(val_loss).mean()\n",
    "            accuracy = class_correct / (validation_dl.batch_size * len(validation_dl))\n",
    "            best_accuracy.append(accuracy)\n",
    "            \n",
    "        print('epoch: {}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}'\n",
    "              .format(epoch, train_loss, val_loss, accuracy))\n",
    "            \n",
    "    best_accuracy = max(best_accuracy)\n",
    "    \n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "055487e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T17:59:42.032157Z",
     "start_time": "2022-01-30T17:59:42.019253Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_unlabeled(unlabeled_ds, threshold=0.95):\n",
    "    '''\n",
    "    if predicted label' confidence is higher then threshold,\n",
    "    labeling y as predicted y\n",
    "    '''\n",
    "    \n",
    "    unlabeled = torch.stack([i[0] for i in unlabeled_ds])\n",
    "    unlabeled_dl = DataLoader(unlabeled, batch_size=8)\n",
    "    \n",
    "    pseudo_labeled = []\n",
    "    index = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, imgs in enumerate(unlabeled_dl):\n",
    "            imgs = imgs.to(device)\n",
    "            \n",
    "            preds = model(imgs)\n",
    "            preds = torch.softmax(preds, dim=1)\n",
    "            conf_preds, y_preds = torch.max(preds, dim=1)\n",
    "            for j, confidence in enumerate(conf_preds):\n",
    "                if confidence >= threshold:\n",
    "                    pseudo_labeled.append((imgs[j].cpu(), y_preds[j].item()))\n",
    "                    idx = (i * unlabeled_dl.batch_size) + j\n",
    "                    index.append(idx)\n",
    "    \n",
    "    print(f'pseudo_labeled size: {len(pseudo_labeled)}')\n",
    "    \n",
    "    return pseudo_labeled, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d65776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T17:59:42.047206Z",
     "start_time": "2022-01-30T17:59:42.033151Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_dataset(pseudo_labeled, index):\n",
    "    '''\n",
    "    add pseudo_labeled to labeled_dataset\n",
    "    '''\n",
    "    \n",
    "    for i in sorted(index, reverse=True):\n",
    "        del unlabeled_ds[i]\n",
    "    \n",
    "    labeled_ds.extend(pseudo_labeled)\n",
    "    \n",
    "    print(f'labeled size: {len(labeled_ds)}, unlabeled size: {len(unlabeled_ds)}')\n",
    "    \n",
    "    return labeled_ds, unlabeled_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "711ca565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T17:59:42.062268Z",
     "start_time": "2022-01-30T17:59:42.049210Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        class_correct = 0\n",
    "        for imgs, labels in mnist_dl:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            preds = model(imgs)\n",
    "            preds = torch.softmax(preds, dim=1)\n",
    "            c = (labels==torch.max(preds, dim=1)[1])\n",
    "            class_correct += c.tolist().count(True)\n",
    "        accuracy = class_correct / (mnist_dl.batch_size * len(mnist_dl))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66aec5ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T17:59:43.487685Z",
     "start_time": "2022-01-30T17:59:42.065280Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07e934d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-30T18:00:00.548365Z",
     "start_time": "2022-01-30T17:59:43.489667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: 480, validation data size: 120\n",
      "epoch: 1, train_loss: 1.1118, val_loss: 0.5431, val_acc: 0.8250\n",
      "epoch: 2, train_loss: 0.2300, val_loss: 0.4345, val_acc: 0.8667\n",
      "epoch: 3, train_loss: 0.0754, val_loss: 0.5072, val_acc: 0.8333\n",
      "epoch: 4, train_loss: 0.0434, val_loss: 0.4651, val_acc: 0.8750\n",
      "epoch: 5, train_loss: 0.0073, val_loss: 0.4367, val_acc: 0.8833\n",
      "0.8837953091684435\n",
      "pseudo_labeled size: 43268\n",
      "labeled size: 43748, unlabeled size: 16132\n"
     ]
    }
   ],
   "source": [
    "train_dl, validation_dl = train_test_split(labeled_ds)\n",
    "train_val(train_dl, validation_dl)\n",
    "print(evaluation())\n",
    "pseudo_labeled, index = test_unlabeled(unlabeled_ds)\n",
    "labeled_ds, unlabeled_ds = update_dataset(pseudo_labeled, index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
